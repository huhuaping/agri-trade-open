---
title: "中国商务部农产品贸易专题网站抓取"
author: "胡华平"
date: "`r Sys.Date()`"
output:
  bookdown::word_document2:
    fig_caption: yes
    toc: yes
    toc_depth: 4
    reference_docx: report-reference.docx
  word_document:
    toc: no
    toc_depth: '4'
  bookdown::html_document2:
    number_sections: yes
    toc: no
    fig_caption: yes
    toc_float: yes
always_allow_html: yes
---

```{r, echo=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE,
                      fig.align='center',fig.width=10, fig.height=7) # Places figures on their own pages
options(
  htmltools.dir.version = FALSE, 
  formatR.indent = 2, width = 55, 
  digits = 2,scipen=999,tinytex.verbose = TRUE,
  knitr.kable.NA = '',
  fig.width=12, fig.height=8)

```

```{r}
require("rvest")
require("stringr")
require("tidyverse")
require("tidyselect")
```

\newpage

# 1.研究目标

目标是把中国商务部发布的《中国农产品进出口月度统计报告》中的所有相关数据整理出来。

- **重点农产品进/出口产品重点市场**（前三市场国家地区）。

初步分析，重点农产品进/出口的国别趋势和关系。

我们关心的重点农产品主要有：

- 大米/稻谷
- 小麦
- 玉米
- 大豆
- 其他


# 2.数据集

## 2.1资料来源1：商务部网站

中国商务部-[农产品贸易专题网站](http://wms.mofcom.gov.cn/article/ztxx/ncpmy/)

**《中国农产品进出口月度统计报告》**:

- 文件标题："中国农产品进出口月度统计报告2020年1月"
- 可下载年限范围：2002/01-2020/02
- 数据频率：月度
- 文件格式：pdf-制式表格


# 3.数据抓取流程


## 3.1数据抓取策略

具体可参看：

- `scrap-v8-04-00-hack-mofcom.Rmd`


## 3.2下载静态pdf

具体R代码可参看：

- `scrap-v8-04-00-hack-mofcom.Rmd`


## 3.3导出pdf为对应的csv文件

### 函数0：基础函数

```{r}
# function for count white spaces
countWhiteSpaces <- function(x) attr(gregexpr("(?<=[^#])[#]+(?=[^#])", x, perl = TRUE)[[1]], "match.length")

# function for seek the whitespace style
###install.packages("mgsub")
###library("mgsub")
str_seek <- function(strs, style=n_style,rep=n_rep){
  out <- mgsub::mgsub(strs, pattern = style, replacement =rep,perl = F)
  return(out)
}


# function for calculate vector modes
getModes <- function(x) {
  ux <- unique(x)
  tab <- tabulate(match(x, ux))
  ux[tab == max(tab)]
}
```

### 函数3：核验原始表格

```{r}
#dt <- rawpage
# check styles
check_tbl <- function(tbl){
  tbl_dt <- tbl %>%
  mutate(n=map(.x = value, .f = countWhiteSpaces)) %>%
  mutate(len = lengths(n), 
         min=map(.x=n, .f=min), 
         max=map(.x=n, .f=max), 
         mode=map(.x = n, .f = getModes))
  return(tbl_dt)
}

#check <- tbl_check(rawpage)

```


### 函数4：得到清洗后的表

```{r}
#tbl_check <- check
# obtain the table output
get_split <- function(tbl_check, style=n_style, rep =n_rep,vars_eng=names_eng){
  len_max <- tbl_check %>% .$len %>% unlist() %>% max()
  tbl_seek <- tbl_check %>%
    mutate(str= if_else(
      len==len_max,gsub("(#){1,50}", "&", value, perl = F), # for full len
      mgsub::mgsub(value, pattern = style, 
                   replacement =rep, perl = F) # for other
      ) ) %>%
    select(str) %>%
    #mutate(str= str_replace(str, "-", "NA")) %>%
    separate(str,into = vars_eng, sep = "&")  %>%
    mutate_at(all_of(vars_eng[-1]), .funs = as.numeric, digits=2)
}

```

### pdf抓取为csv

#### 异常提示

2002/01-2003/02：一张表跨两页。只有出口。**解决办法**：已处理好。
-   2002/01和2002/02，没有上年同期金额。

2003-03~2004-12：省份异常，安徽开头，重庆结尾。**解决办法**：已处理好。

2005-01~2005-12：省份异常，上海开头，黑龙江结尾。**解决办法**：已处理好。
- 2005-02 pdf格式异常，无法读取。**解决办法**：手动处理

2006-01：省份排序异常。上海开头，黑龙江结尾。**解决办法**：已处理好。

2016-09: 进出口表被整合在一块，没法识别。**解决办法**：手动处理/上年同期。


#### 抓取代码

```{r}
# install.packages("pdftools")
library("pdftools")

# read backup urls
tbl_urls <- openxlsx::read.xlsx("tbl-urls-backup.xlsx",colNames=T) 

# files pdf path
### you should change the dir according to the purpose
files_dir <- here::here("data", "v8", "04-trade-mofcom", "pdf")


files_html <- list.files(str_c(files_dir,"/"))
page_url <- str_c(files_dir, files_html, sep = "/")

# table the files
tbl_files <- tibble(name_file=files_html,
                    size = round(file.size(page_url)/1024,0)) %>%
  add_column(ID = 1:nrow(.), .before = "name_file") %>%
  mutate(year= str_extract(name_file, "(\\d{4})(?=-)"),
         month= str_extract(name_file, "(?<=-)(\\d{2})")) %>%
  mutate(month_num= as.numeric(month)) %>%
  mutate(path_file = paste0("pdf/", name_file)) 


# set pars for seek whitespace style
n_start <- c(61,51,26,1) # not zero
n_end <-  c(70,60,50,25)
n_style <- paste0("(#){", n_start, ",", n_end, "}")
n_rep <-  c("&&&&","&&&", "&&", "&" )

list_province <- c("北京","天津","河北","山西","内蒙古","辽宁","吉林","黑龙江","上海","江苏","浙江","安徽","福建","江西","山东","河南","湖北","湖南","广东","广西","海南","重庆","四川","贵州","云南","西藏","陕西","甘肃","青海","宁夏","新疆")

i <- 2002
j <- 2
k <- 1

# loop years
for (i in 2020:2020) {
  # filter year and month
  tbl_ym <- tbl_files %>%
    filter(year==i)

  i_len <- nrow(tbl_ym)
  # loop months
  for (j in c(1:3)) {
    # read pdf as text
    pth<- tbl_ym$path_file[j]
    txt <- suppressWarnings(suppressMessages(pdf_text(pth)))
    
    
    # focus the pages
    page_target <- which(str_detect(txt, "北京|新疆"))
    page_raw <- txt[page_target]
    if (length(page_raw)==0) stop("pdf文件读取出错，请核实！")
    
    # loop province
    #k <- 22
    tbl_province <- NULL
    for (k in 1:length(list_province)){
      # detect the page which contain certain province
      page_province <- which(str_detect(txt, list_province[k]))
      # skip iteration and go to next iteration：k=22 in 2002-2
      if (length(page_province)==0) {
        print(paste0(list_province[k], "不在pdf表格中，请核实！"))
        next
        }
    
      # pattern to obtain data
      pattern_province <- paste0("(",list_province[k], ".*)(?=\r\n)")
      
      dt_province <- str_extract_all(txt[page_target], 
                                     pattern_province) %>%
        unlist() %>%
        as_tibble() %>%
        mutate(value=gsub(" ", "#", value))%>%
        mutate(value=gsub(",", "", value)) %>%
        mutate(value=gsub("%", "", value))
      
      check <- check_tbl(dt_province)
      
      # create names
      n_cols <- max(check$len)
      names_eng <- c("V0", paste0("V",1:n_cols ))
      
      
      tbl_split <- get_split(check,vars_eng = names_eng) %>%
        add_column(page=page_province)
      
      tbl_province <- bind_rows(tbl_province, tbl_split)
      print(paste0("第",k,"个省：",list_province[k]))
    }
    
    # obtain currency unit:
      detect_unit <- str_extract(page_raw, "(单位.+)|(金额.+)")[1]
      
      currency <- str_extract_all(detect_unit, "(?<=：|单位)(.+)") %>%
        str_trim(side = "both") %>%
        str_replace("：", "")
      if (length(currency)==0) stop("金额单位无法识别，请核实！")
      tbl_unit <- tibble(page=page_target, currency= currency )
      
    
      # obtain trade type: export or import
      title_target <- which(str_detect(txt, "表.+分地区"))
      txt_page <- txt[title_target]
      detect_title <- str_extract(txt_page, "(表.+分地区.{2}情况)")
      type <- str_extract(detect_title, ".{2}(?=情况)")
      if (length(page_raw)==2 & (page_target[1]!=page_target[2])){
        tbl_title<- tibble(page=page_target, type=type)
      } else {
        tbl_title<- tibble(page=title_target, type=type)
      }
    
      tbl_out <- tbl_province %>%
        left_join(., tbl_unit, by = "page") %>%
        left_join(., tbl_title, by = "page") %>%
          add_column(year= i, .before = "V0") %>%
          add_column(month= str_pad(j, width = 2, pad = "0"), 
                     .before = "V0") %>%
        select(year, month, type, currency, everything()) %>%
        mutate(V0=str_replace(V0, "省|市|自治区", ""),
               V0= str_replace(V0,"壮族|回族|维吾尔", "")) %>%
        mutate(V0= factor(V0, levels=list_province)) %>%
        arrange(type, V0)
  
   # check actual rows and theory rows
    rows_act <- nrow(tbl_out) 
    
    if (length(title_target) == 1){
       rows_theory <- 31
    } else if (length(title_target) == 2){
       rows_theory <- 31*2        # two table
    }
    
    
  if (rows_theory == rows_act) {
    print(paste0(i,"年", j, "月。恭喜！实际数据点数与理论一致！数据点数=", rows_act))
  } else {
    print(paste0(i,"年", j, "月。不妙！实际数据点数与理论不一致！实际数=", rows_act, ";理论数=", rows_theory))
  }
  
  # checking when there were inconsistent
  ttt <- tbl_out %>%
    group_by(type) %>%
    summarize(n=n(), .groups="drop")
  
  # wait to see the result
  Sys.sleep(1)
  
 if (rows_theory != rows_act) warning("请检查，数据量与预期不一致！")
  
  # files csv path
  path_csv <- paste0("csv-01-region/",i, "-",str_pad(j, width = 2, pad = "0"), ".csv")
  write.csv(tbl_out, path_csv, row.names = F)

  }
}

```

## 3.4合并全部csv表格有效数据

### 异常提示

2002/01：贸易类型没有识别出来。**解决办法**：已处理好。

### 合并代码

```{r, eval=FALSE, echo=FALSE}
# set for chinese header
vars_chn <- c("年度","月份", "序号","类章序号","类章名目" ,
             "出口_当月", "出口_累计","进口_当月", "进口_累计",
             "累计同期变动_出口","累计同期变动_进口")
vars_eng <- c("Year","Month", "ID",
             "cat", paste0("X", 1:7))
cat_list <- paste0(str_pad(c(1:4,7:8,10:11,15,31,51:52), width = 2, pad = "0"),
                   "章")

# files path
csv_dir <- here::here("data", "v8", "04-trade-mofcom", "csv-01-region")
csv_files <- list.files(str_c(csv_dir,"/"))
csv_url <- str_c(csv_dir, csv_files, sep = "/")


# i <-2 length(csv_files)
tbl_out <- NULL
for (i in 1:length(csv_files)) {
  path_csv <- csv_files[i]
  
  # table for checking with the csv file
  tbl_tem <- read.csv(csv_url[i], header = T)  
  
  # check
  if(is.na(tbl_tem$V0)) stop("省份识别有问题，请核实！")
  if(is.na(tbl_tem$currency)) stop("单位识别有问题，请核实！")
  
  # add columns if needed
  n_V<- sum(str_detect(names(tbl_tem), "V\\d{1}"))
  if (n_V==3){
    tbl_tidy <- tbl_tem %>%
      rename_at(vars("V2"),~"V3") %>%
      add_column(V2="", .after = "V1") %>%
      mutate(V2=as.numeric(V2))
  } else {
    tbl_tidy <- tbl_tem 
  }
  
  # consistency of the unit and value
  tbl_value <- tbl_tidy %>%
    mutate(V1=ifelse(currency=="美元", V1/10000, V1),
           V2=ifelse(currency=="美元", V2/10000, V2)) %>%
    mutate(currency=ifelse(currency=="美元", "万美元", currency))
  
  # row bind 
  tbl_out <- bind_rows(tbl_out, tbl_value)
  print(csv_files[i])
}

# checking when there were inconsistent
ttt <- tbl_out %>%
  group_by(V0) %>%
  summarize(n=n())

```



## 3.5写出有效数据

```{r}
path_out <- str_c("tbl-mofcom-agri-trade-region-", Sys.Date(),".csv")
write.csv(tbl_out, path_out, row.names = F)
```